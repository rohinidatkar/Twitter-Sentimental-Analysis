{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008235eb",
   "metadata": {},
   "source": [
    "# Data Science and Machine Learning Internship Program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86f182",
   "metadata": {},
   "source": [
    "#  Mini Project 3 –    Twitter Sentimental Analysis Using NLP and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835648d2",
   "metadata": {},
   "source": [
    "# Scenario: \n",
    "\n",
    "By analyzing text data, we can find meaningful insights from non-numeric data that\n",
    "can help us achieve our objective. With the help of NLP and its concepts, we can do it. Twitter is\n",
    "one of the biggest platforms that people use to write their messages, express their feelings\n",
    "about a particular topic, and share knowledge in the form of text. By analyzing text data, we can\n",
    "make good decisions for different use cases like judging the sentiment of the human tweets, and\n",
    "any product review/comments can tell us the performance of a product in the market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec45d88",
   "metadata": {},
   "source": [
    "# Importing Neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ffde7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034fef07",
   "metadata": {},
   "source": [
    "# Task 1. Read the Data from the Given excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f8c57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "data = pd.read_csv('Twitter_Data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea9900",
   "metadata": {},
   "source": [
    "# Task 2. Change our dependent variable to categorical. ( 0 to “Neutral,” -1 to “Negative”, 1 to “Positive”)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f24e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...  Negative\n",
       "1  talk all the nonsense and continue all the dra...   Neutral\n",
       "2  what did just say vote for modi  welcome bjp t...  Positive\n",
       "3  asking his supporters prefix chowkidar their n...  Positive\n",
       "4  answer who among these the most powerful world...  Positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map numeric categories to strings\n",
    "category_mapping = {0: \"Neutral\", -1: \"Negative\", 1: \"Positive\"}\n",
    "data['category'] = data['category'].map(category_mapping)\n",
    "\n",
    "# Verify changes\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb2014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a9c56d",
   "metadata": {},
   "source": [
    "# Task 3. Do Missing value analysis and drop all null/missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977fd4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    0\n",
       "category      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "data.isnull().sum()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Verify no missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd3f1e",
   "metadata": {},
   "source": [
    "# Task 4. Do text cleaning. (remove every symbol except alphanumeric, transform all words tolower case, and remove punctuation and stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2dc61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data['cleaned_tweet'] = data['clean_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55877858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         modi promised minimum government maximum gover...\n",
       "1                    talk nonsense continue drama vote modi\n",
       "2         say vote modi welcome bjp told rahul main camp...\n",
       "3         asking supporters prefix chowkidar names modi ...\n",
       "4         answer among powerful world leader today trump...\n",
       "                                ...                        \n",
       "162975    456 crores paid neerav modi recovered congress...\n",
       "162976    dear rss terrorist payal gawar modi killing 10...\n",
       "162977                         cover interaction forum left\n",
       "162978    big project came india modi dream project happ...\n",
       "162979    ever listen like gurukul discipline maintained...\n",
       "Name: cleaned_tweet, Length: 162969, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23765a4",
   "metadata": {},
   "source": [
    "# Task 5. Create a new column and find the length of each sentence (how many words they contain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8adcb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each sentence\n",
    "data['sentence_length'] = data['cleaned_tweet'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d7e175",
   "metadata": {},
   "source": [
    "# Task 6. Split data into dependent(X) and independent(y) dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e53fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the target variable\n",
    "X = data['cleaned_tweet']\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e38bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         modi promised minimum government maximum gover...\n",
       "1                    talk nonsense continue drama vote modi\n",
       "2         say vote modi welcome bjp told rahul main camp...\n",
       "3         asking supporters prefix chowkidar names modi ...\n",
       "4         answer among powerful world leader today trump...\n",
       "                                ...                        \n",
       "162975    456 crores paid neerav modi recovered congress...\n",
       "162976    dear rss terrorist payal gawar modi killing 10...\n",
       "162977                         cover interaction forum left\n",
       "162978    big project came india modi dream project happ...\n",
       "162979    ever listen like gurukul discipline maintained...\n",
       "Name: cleaned_tweet, Length: 162969, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bb6a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Negative\n",
       "1          Neutral\n",
       "2         Positive\n",
       "3         Positive\n",
       "4         Positive\n",
       "            ...   \n",
       "162975    Negative\n",
       "162976    Negative\n",
       "162977     Neutral\n",
       "162978     Neutral\n",
       "162979    Positive\n",
       "Name: category, Length: 162969, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74da48a",
   "metadata": {},
   "source": [
    "# Task 7. Do operations on text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fed6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences\n",
    "max_length = max(data['sentence_length'])\n",
    "X_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode target variable\n",
    "y_encoded = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263a53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162969 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Negative  Neutral  Positive\n",
       "0           True    False     False\n",
       "1          False     True     False\n",
       "2          False    False      True\n",
       "3          False    False      True\n",
       "4          False    False      True\n",
       "...          ...      ...       ...\n",
       "162975      True    False     False\n",
       "162976      True    False     False\n",
       "162977     False     True     False\n",
       "162978     False     True     False\n",
       "162979     False    False      True\n",
       "\n",
       "[162969 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1129d2",
   "metadata": {},
   "source": [
    "# Task 8. • Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52994c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "input_length = max_length\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: Neutral, Negative, Positive\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de5499",
   "metadata": {},
   "source": [
    "# Split the Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "255b51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ef406",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4eb2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1630/1630 [==============================] - 393s 239ms/step - loss: 0.4992 - accuracy: 0.8141 - val_loss: 0.3313 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "1630/1630 [==============================] - 377s 231ms/step - loss: 0.2754 - accuracy: 0.9158 - val_loss: 0.2850 - val_accuracy: 0.9158\n",
      "Epoch 3/10\n",
      "1630/1630 [==============================] - 373s 229ms/step - loss: 0.1997 - accuracy: 0.9423 - val_loss: 0.3040 - val_accuracy: 0.9092\n",
      "Epoch 4/10\n",
      "1630/1630 [==============================] - 384s 236ms/step - loss: 0.1529 - accuracy: 0.9567 - val_loss: 0.3631 - val_accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "1630/1630 [==============================] - 406s 249ms/step - loss: 0.1186 - accuracy: 0.9667 - val_loss: 0.3677 - val_accuracy: 0.8988\n",
      "Epoch 6/10\n",
      "1630/1630 [==============================] - 371s 227ms/step - loss: 0.0931 - accuracy: 0.9733 - val_loss: 0.4180 - val_accuracy: 0.8865\n",
      "Epoch 7/10\n",
      "1630/1630 [==============================] - 364s 223ms/step - loss: 0.0738 - accuracy: 0.9784 - val_loss: 0.4659 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "1630/1630 [==============================] - 371s 227ms/step - loss: 0.0586 - accuracy: 0.9829 - val_loss: 0.5451 - val_accuracy: 0.8836\n",
      "Epoch 9/10\n",
      "1630/1630 [==============================] - 376s 231ms/step - loss: 0.0464 - accuracy: 0.9866 - val_loss: 0.6042 - val_accuracy: 0.8751\n",
      "Epoch 10/10\n",
      "1630/1630 [==============================] - 375s 230ms/step - loss: 0.0371 - accuracy: 0.9889 - val_loss: 0.6751 - val_accuracy: 0.8797\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f21574",
   "metadata": {},
   "source": [
    "# Task 9. Normalize the prediction as same as the original data(prediction might be in decimal, so whoever is nearest to 1 is predicted as yes and set other as 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2007e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019/1019 [==============================] - 30s 29ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.80      0.81      0.81      7152\n",
      "    Negative       0.91      0.92      0.91     11067\n",
      "    Positive       0.90      0.89      0.89     14375\n",
      "\n",
      "    accuracy                           0.88     32594\n",
      "   macro avg       0.87      0.87      0.87     32594\n",
      "weighted avg       0.88      0.88      0.88     32594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and normalize predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "y_true = y_test.values.argmax(axis=-1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred_classes, target_names=category_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8257e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
